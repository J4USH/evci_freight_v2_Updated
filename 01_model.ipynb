{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVCI siting model\n",
    "\n",
    "> **API**: The mathematical formulation is defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import shapely\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evci_tool.config import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def score(r,s_df_distances,j,i,hj,k,backoff=True, backoff_factor=1):\n",
    "    \"This function computes the utilization score of each site.\"\n",
    "    \n",
    "    distance_from_i = s_df_distances[s_df_distances > 0][i].sort_values()/1e3\n",
    "    closer_to_i = distance_from_i[distance_from_i <= 5.0]\n",
    "    try:\n",
    "        congestion = float(s_df_distances.loc[i]['Traffic congestion'])\n",
    "    except:\n",
    "        congestion = 1.0\n",
    "\n",
    "    nw = r['qjworking'][j][hj] * r['djworking'][j][hj] * r['pj'][k] * congestion\n",
    "    nh = r['qjholiday'][j][hj] * r['djholiday'][j][hj] * r['pj'][k] * congestion\n",
    "\n",
    "    if backoff:\n",
    "        for el in closer_to_i:\n",
    "            nw *= (1 - np.exp(-el*backoff_factor))\n",
    "            nh *= (1 - np.exp(-el*backoff_factor))\n",
    "\n",
    "    tw = th = 0\n",
    "    if (r['Cij'][j][i] > 0): tw = nw * (r['tj'][j]/r['Cij'][j][i])\n",
    "    if (r['Cij'][j][i] > 0): th = nh * (r['tj'][j]/r['Cij'][j][i])\n",
    "\n",
    "    uw = uh = r['tj'][j]\n",
    "    if (tw <= r['tj'][j]): uw = tw \n",
    "    if (th <= r['tj'][j]): uh = th\n",
    "\n",
    "    vw = vh = 0\n",
    "    if (tw > r['tj'][j]): vw = (tw - r['tj'][j]) * (r['Cij'][j][i]/r['tj'][j])\n",
    "    if (th > r['tj'][j]): vh = (th - r['tj'][j]) * (r['Cij'][j][i]/r['tj'][j])\n",
    "\n",
    "    norm_uw, norm_uh = uw/r['tj'][j], uh/r['tj'][j]\n",
    "    \n",
    "    if nw>0: norm_vw = vw/nw\n",
    "    else: norm_vw = 0\n",
    "    if nh>0: norm_vh = vh/nh\n",
    "    else: norm_vh = 0\n",
    "\n",
    "    return norm_uw, norm_uh, norm_vw, norm_vh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `r`: a dictionary of global parameters read from the xlsx files.\n",
    "2. `s_df_distances`: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\n",
    "3. `j`: string indicating specific charger type\n",
    "4. `i`: integer indicating a specific site\n",
    "5. `hj`: \n",
    "6. `k`: integer year (1, 2 or 3 of the policy)\n",
    "7. `backoff`: a boolean indicating whether backoff should be incorporated\n",
    "8. `backoff_factor`: a float weighting factor for the backoff (mostly empirically selected)\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "1. `norm_uw`: float indicating normalized utilization on a typical working day\n",
    "2. `norm_uh`: float indicating normalized utilization on a typical holiday\n",
    "3. `norm_vw`: float indicating number of vehicles not utilizing charging on a working day\n",
    "4. `norm_vh`: float indicating number of vehicles not utilizing charging on a holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def capex(r,i):\n",
    "    \"This function computes the capex requirements of each site\"\n",
    "    retval = 0\n",
    "    for j in r['C']:\n",
    "        retval += r['Cij'][j][i]*r['Kj'][j] + r['Wi'][i] * r['di'][i] * r['Cij'][j][i]\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `r`: a dictionary of global parameters read from the xlsx files.\n",
    "2. `i`: integer indicating a specific site\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "integer. Capex value for a given site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def opex(r,s_df_distances,i):\n",
    "    \"This function computes the opex for each site.\"\n",
    "    op_e = 0\n",
    "    op_l = 0\n",
    "\n",
    "    for k in r['years_of_analysis']:\n",
    "        for j in r['C']:\n",
    "            for h in range(int(r['timeslots'][j])):\n",
    "                sw, sh, _, _ = score (r,s_df_distances,j,i,h,k)\n",
    "                op_e += 300 * r['Cij'][j][i] * sw * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Eg'][j][h] + (1-r['l'][j][h]) * r['Er'][j][h])\n",
    "                op_e +=  65 * r['Cij'][j][i] * sh * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Eg'][j][h] + (1-r['l'][j][h]) * r['Er'][j][h])\n",
    "    op_l = r['Li'][i] * r['Ai'][i] + r['CH'][i] + r['CK'][i]\n",
    "    return op_e + op_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `r`: a dictionary of global parameters read from the xlsx files.\n",
    "2. `s_df_distances`: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\n",
    "3. `i`: integer indicating a specific site\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "integer opex value for a given site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def margin(r,s_df_distances,i):\n",
    "    \"This function computes the margins per site.\"\n",
    "    margin_e = 0\n",
    "    margin_l = 0\n",
    "\n",
    "    for k in r['years_of_analysis']:\n",
    "        for j in r['C']:\n",
    "            for h in range(int(r['timeslots'][j])):\n",
    "                sw, sh, _, _ = score (r,s_df_distances,j,i,h,k)\n",
    "                margin_e += 300 * r['Cij'][j][i] * sw * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Mg'][j][h] + (1-r['l'][j][h]) * r['Mr'][j][h])\n",
    "                margin_e +=  65 * r['Cij'][j][i] * sh * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Mg'][j][h] + (1-r['l'][j][h]) * r['Mr'][j][h])\n",
    "    margin_l = r['Bi'][i] * r['Ai'][i] + r['MH'][i] + r['MK'][i]\n",
    "    return margin_e + margin_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `r`: a dictionary of global parameters read from the xlsx files.\n",
    "2. `s_df_distances`: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\n",
    "3. `i`: integer indicating a specific site\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "integer margin value of a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def run_analysis(m,s,t,g,ui_inputs,s_df,backoff_factor=1):\n",
    "    \"This function runs analysis for a given set of sites.\"\n",
    "\n",
    "    r = read_globals(m,s,t,g,ui_inputs)\n",
    "    \n",
    "    u_df = pd.DataFrame(columns=['utilization', \n",
    "                             'unserviced', \n",
    "                             'capex', \n",
    "                             'opex', \n",
    "                             'margin', \n",
    "                             'max vehicles', \n",
    "                             'estimated vehicles'\n",
    "                             ])    \n",
    "    s_df_crs = gpd.GeoDataFrame(s_df, crs='EPSG:4326')\n",
    "    s_df_crs = s_df_crs.to_crs('EPSG:5234')\n",
    "    s_df_distances = s_df_crs.geometry.apply(lambda g: s_df_crs.distance(g))      \n",
    "    \n",
    "    s_df_distances['Traffic congestion'] = s['sites']['Traffic congestion']\n",
    "    \n",
    "    Nc = s_df.shape[0]\n",
    "    \n",
    "    for i in tqdm(range(Nc)):\n",
    "        max_vehicles = 0\n",
    "        # run through selected charger types\n",
    "        for j in r['M']:\n",
    "            max_vehicles += r['timeslots'][j]*r['Cij'][j][i]\n",
    "        max_vehicles = int(np.round(max_vehicles,0))\n",
    "        op_e = 0\n",
    "        op_l = 0\n",
    "        margin_e = 0\n",
    "        margin_l = 0\n",
    "        year_u_avg = np.array([])\n",
    "        year_v_avg = np.array([])\n",
    "        for k in r['years_of_analysis']:\n",
    "            chargertype_u_avg = np.array([])\n",
    "            chargertype_v_avg = np.array([])\n",
    "            for j in r['C']:\n",
    "                uw_day_avg = np.array([])\n",
    "                uh_day_avg = np.array([])\n",
    "                vw_day_avg = np.array([])\n",
    "                vh_day_avg = np.array([])              \n",
    "                for h in range(int(r['timeslots'][j])):\n",
    "                    uw, uh, vw, vh = score (r,s_df_distances,j,i,h,k,backoff_factor=backoff_factor)\n",
    "                    uw_day_avg = np.append(uw_day_avg, uw)\n",
    "                    uh_day_avg = np.append(uh_day_avg, uh)\n",
    "                    vw_day_avg = np.append(vw_day_avg, vw)\n",
    "                    vh_day_avg = np.append(vh_day_avg, vh)                  \n",
    "                    op_e += 300 * r['Cij'][j][i] * uw * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Eg'][j][h] + (1-r['l'][j][h]) * r['Er'][j][h])\n",
    "                    op_e +=  65 * r['Cij'][j][i] * uh * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Eg'][j][h] + (1-r['l'][j][h]) * r['Er'][j][h])            \n",
    "                    margin_e += 300 * r['Cij'][j][i] * uw * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Mg'][j][h] + (1-r['l'][j][h]) * r['Mr'][j][h])\n",
    "                    margin_e +=  65 * r['Cij'][j][i] * uh * r['tj'][j] * r['Dj'][j] * (r['l'][j][h] * r['Mg'][j][h] + (1-r['l'][j][h]) * r['Mr'][j][h])        \n",
    "                weighted_u = (300.0*uw_day_avg.mean() + 65.0*uh_day_avg.mean()) / 365.0\n",
    "                weighted_v = (300.0*vw_day_avg.mean() + 65.0*vh_day_avg.mean()) / 365.0\n",
    "                chargertype_u_avg = np.append(chargertype_u_avg, weighted_u)\n",
    "                chargertype_v_avg = np.append(chargertype_v_avg, weighted_v)\n",
    "            year_u_avg = np.append(year_u_avg, chargertype_u_avg.mean())\n",
    "            year_v_avg = np.append(year_v_avg, chargertype_v_avg.mean())\n",
    "            op_l += r['Li'][i] * r['Ai'][i] + r['CH'][i] + r['CK'][i]\n",
    "            margin_l += r['Bi'][i] * r['Ai'][i] + r['MH'][i] + r['MK'][i]\n",
    "        site_capex = capex(r,i)\n",
    "        estimated_vehicles = np.round(year_u_avg.mean()*max_vehicles,0)\n",
    "        u_df.loc[i] = [ year_u_avg.mean(), \n",
    "                       year_v_avg.mean(),\n",
    "                       site_capex,\n",
    "                       op_e + op_l,\n",
    "                       margin_e + margin_l,\n",
    "                       max_vehicles,\n",
    "                       estimated_vehicles\n",
    "                       ]\n",
    "    return u_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `m`: dataframe of model parameters (from model.xlsx)\n",
    "2. `s`: dataframe of sites (from sites.xlsx)\n",
    "3. `t`: dataframe of traffic profile (from traffic.xlsx)\n",
    "4. `g`: dataframe of grid parameters (from grid.xlsx)\n",
    "5. `ui_inputs`: json object of user selected inputs from the UI\n",
    "6. `s_df`: pre-processed geopandas dataframe with each point stored as shapely point object\n",
    "7. `backoff_factor`: a float value of backoff to cater for neighborhood (empirical)\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "A dataframe of utilization values for all sites."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
