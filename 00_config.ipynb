{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVCI config\n",
    "\n",
    "> **API**: The inputs are specified through 4 excel sheets for frieght corridor analysis. The python code reads these inputs parameters from the following excel sheets for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. model.xlsx - This contains all the global parameters that are model specific. They remain valid for every corridor that needs analysis.\n",
    "2. sites.xlsx - This contains a list of sites, with their latitude and longitude for analysis. This is an initial list of sites. This file needs to be created for each freight corridor\n",
    "3. traffic.xlsx - This contains a typical traffic profile around the sites for each freight corridor.\n",
    "4. grid.xlsx - This contains information about neighboring distribution transformers from where the chargers deployed at each site will draw power from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def setup_and_read_data(corridor:str, input_path='input/', output_path='output/'):\n",
    "    \"This function sets up paths and reads input excel files for a specified corridor\"\n",
    "\n",
    "    INPUT_PATH = input_path + corridor + '/'\n",
    "    OUTPUT_PATH = output_path + corridor + '/'\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.mkdir (output_path + corridor)\n",
    "        \n",
    "    model   = pd.read_excel(input_path + \"model.xlsx\",sheet_name=['charger_specific','battery_specific','others'])\n",
    "    sites   = pd.read_excel(INPUT_PATH + \"sites.xlsx\",sheet_name=['sites'])\n",
    "    traffic = pd.read_excel(INPUT_PATH + \"traffic.xlsx\",sheet_name=['profile'])\n",
    "    grid    = pd.read_excel(INPUT_PATH + \"grid.xlsx\",sheet_name=['grid'])\n",
    "    \n",
    "    return model, sites, traffic, grid, INPUT_PATH, OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `corridor`: a string that identifies the corridor being analyzed (e.g. chandigarh_leh)\n",
    "2. `input_path`: a string denoting base directory under which input files (xlsx and shape files) are available for analysis. Default is `'input/'`\n",
    "3. `output_path`: a string denoting base directory under which output files will be stored. Default is `'output/'`\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "1. `model`: dataframe of model parameters (from model.xlsx)\n",
    "2. `sites`: dataframe of sites (from sites.xlsx)\n",
    "3. `traffic`: dataframe of traffic profile (from traffic.xlsx)\n",
    "4. `grid`: dataframe of grid parameters (from grid.xlsx)\n",
    "5. `INPUT_PATH`: a string indicating the input_path (e.g. input/chandigarh_leh/)\n",
    "6. `OUTPUT_PATH`: a string indicating the output path (e.g. output/chandigarh_leh/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example usage\n",
    "m,s,t,g,INPUT_PATH,OUTPUT_PATH = setup_and_read_data('chandigarh_karnal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data availability check\n",
    "\n",
    "Let's check if the four excel sheets provided have the correctly named worksheets within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "model_sheets = ['charger_specific', 'battery_specific', 'others']\n",
    "sites_sheets = ['sites']\n",
    "traffic_sheets = ['profile']\n",
    "grid_sheets = ['grid']\n",
    "\n",
    "def data_availability_check(m,s,t,g): \n",
    "    \"This function checks if the excel files contain the mandatory worksheets.\"\n",
    "    \n",
    "    retval = []\n",
    "    \n",
    "    if list(m.keys()) != model_sheets: retval.append('model')\n",
    "    if list(s.keys()) != sites_sheets: retval.append('sites')\n",
    "    if list(t.keys()) != traffic_sheets: retval.append('traffic')\n",
    "    if list(g.keys()) != grid_sheets: retval.append('grid')\n",
    "    \n",
    "    #assert data_availability_check(list(m.keys()),model_sheets) == True, \\\n",
    "    #  f\"model.xlsx must contain the sheets: {model_sheets}\" \n",
    "    #assert data_availability_check(list(s.keys()),['sites']) == True, \\\n",
    "    #  f\"sites.xlsx must contain the sheet {sites_sheets}\" \n",
    "    #assert data_availability_check(list(t.keys()),['profile']) == True, \n",
    "    #  f\"traffic.xlsx must contain the sheet {traffic_sheets}\" \n",
    "    #assert data_availability_check(list(g.keys()),['grid']) == True, \\\n",
    "    #  f\"grid.xlsx must contain the sheet {grid_sheets}\"\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `m`: dataframe of model parameters (from model.xlsx)\n",
    "2. `s`: dataframe of sites (from sites.xlsx)\n",
    "3. `t`: dataframe of traffic profile (from traffic.xlsx)\n",
    "4. `g`: dataframe of grid parameters (from grid.xlsx)\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "A list of xlsx file names wiht missing mandatory sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_availability_check(m,s,t,g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data integrity check\n",
    "\n",
    "Let's now check if any of the mandatory columns in each of the worksheets are all empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def data_integrity_check(m,s,t,g, verbose=False):\n",
    "    \"This function checks for integrity of excel data by checking missing values.\"\n",
    "    missing = []\n",
    "    \n",
    "    for x in [m,s,t,g]:\n",
    "        tmpx = {}\n",
    "        for k in x.keys():\n",
    "            total = x[k].shape[0]\n",
    "            tmpx[k] = []\n",
    "            for c in x[k].columns:\n",
    "                if sum(pd.isna(x[k][c])) > 0:\n",
    "                    if verbose: print(f\"Column '{c}' of '{k}' has {sum(pd.isna(x[k][c]))}/{total} missing values\")\n",
    "                    tmpx[k].append(c)\n",
    "        missing.append(tmpx)\n",
    "                    \n",
    "    return missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `m`: dataframe of model parameters (from model.xlsx)\n",
    "2. `s`: dataframe of sites (from sites.xlsx)\n",
    "3. `t`: dataframe of traffic profile (from traffic.xlsx)\n",
    "4. `g`: dataframe of grid parameters (from grid.xlsx)\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "A dictionary of missing columns with their corresponding xlsx filename and worksheet name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'charger_specific': ['Range',\n",
       "   'UoM',\n",
       "   '2W',\n",
       "   '3WS',\n",
       "   '4WS',\n",
       "   '4WF',\n",
       "   'Unnamed: 9',\n",
       "   '2W.1',\n",
       "   '3WS.1',\n",
       "   '4WS.1',\n",
       "   '4WF.1'],\n",
       "  'battery_specific': ['Parameter',\n",
       "   'Value',\n",
       "   'Range',\n",
       "   'User Input?',\n",
       "   'Unnamed: 4',\n",
       "   'Same battery swapping station is used for 2W and 3W',\n",
       "   'Unnamed: 6',\n",
       "   'Unnamed: 7',\n",
       "   'Unnamed: 8',\n",
       "   'Unnamed: 9',\n",
       "   'Unnamed: 10',\n",
       "   'Unnamed: 11',\n",
       "   'Unnamed: 12',\n",
       "   'Unnamed: 13',\n",
       "   'Unnamed: 14',\n",
       "   'Unnamed: 15',\n",
       "   'Unnamed: 16',\n",
       "   'Unnamed: 17',\n",
       "   'Unnamed: 18',\n",
       "   'Unnamed: 19'],\n",
       "  'others': ['Range']},\n",
       " {'sites': ['Address']},\n",
       " {'profile': []},\n",
       " {'grid': []}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_integrity_check(m,s,t,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Range' of 'charger_specific' has 12/15 missing values\n",
      "Column 'UoM' of 'charger_specific' has 8/15 missing values\n",
      "Column '2W' of 'charger_specific' has 8/15 missing values\n",
      "Column '3WS' of 'charger_specific' has 8/15 missing values\n",
      "Column '4WS' of 'charger_specific' has 8/15 missing values\n",
      "Column '4WF' of 'charger_specific' has 8/15 missing values\n",
      "Column 'Unnamed: 9' of 'charger_specific' has 15/15 missing values\n",
      "Column '2W.1' of 'charger_specific' has 9/15 missing values\n",
      "Column '3WS.1' of 'charger_specific' has 9/15 missing values\n",
      "Column '4WS.1' of 'charger_specific' has 9/15 missing values\n",
      "Column '4WF.1' of 'charger_specific' has 9/15 missing values\n",
      "Column 'Parameter' of 'battery_specific' has 10/18 missing values\n",
      "Column 'Value' of 'battery_specific' has 10/18 missing values\n",
      "Column 'Range' of 'battery_specific' has 18/18 missing values\n",
      "Column 'User Input?' of 'battery_specific' has 10/18 missing values\n",
      "Column 'Unnamed: 4' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Same battery swapping station is used for 2W and 3W' of 'battery_specific' has 11/18 missing values\n",
      "Column 'Unnamed: 6' of 'battery_specific' has 11/18 missing values\n",
      "Column 'Unnamed: 7' of 'battery_specific' has 11/18 missing values\n",
      "Column 'Unnamed: 8' of 'battery_specific' has 16/18 missing values\n",
      "Column 'Unnamed: 9' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 10' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 11' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 12' of 'battery_specific' has 17/18 missing values\n",
      "Column 'Unnamed: 13' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 14' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 15' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 16' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 17' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 18' of 'battery_specific' has 18/18 missing values\n",
      "Column 'Unnamed: 19' of 'battery_specific' has 17/18 missing values\n",
      "Column 'Range' of 'others' has 8/8 missing values\n",
      "Column 'Address' of 'sites' has 48/48 missing values\n",
      "Column 'Traffic congestion' of 'sites' has 48/48 missing values\n",
      "Column 'Year for Site recommendation' of 'sites' has 48/48 missing values\n",
      "Column 'Hoarding/Kiosk (1 is yes & 0 is no)' of 'sites' has 48/48 missing values\n",
      "Column 'Hoarding margin' of 'sites' has 48/48 missing values\n",
      "Column 'Kiosk margin' of 'sites' has 48/48 missing values\n",
      "Column 'Available area' of 'sites' has 48/48 missing values\n",
      "Column 'Upfront cost per sqm (land)' of 'sites' has 48/48 missing values\n",
      "Column 'Yearly cost per sqm (land)' of 'sites' has 48/48 missing values\n",
      "Column 'Upfront cost per sqm (kiosk)' of 'sites' has 48/48 missing values\n",
      "Column 'Yearly cost per sqm (kiosk)' of 'sites' has 48/48 missing values\n",
      "Column 'Upfront cost per sqm (hoarding)' of 'sites' has 48/48 missing values\n",
      "Column 'Yearly cost per sqm (hoarding)' of 'sites' has 48/48 missing values\n",
      "Column 'Battery swap available' of 'sites' has 48/48 missing values\n",
      "Column 'Longitude' of 'grid' has 1/4 missing values\n",
      "Column 'Latitude' of 'grid' has 1/4 missing values\n",
      "Column 'Tariff' of 'grid' has 4/4 missing values\n",
      "Column 'Power Outage' of 'grid' has 4/4 missing values\n",
      "Column 'Available load' of 'grid' has 4/4 missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'charger_specific': ['Range',\n",
       "   'UoM',\n",
       "   '2W',\n",
       "   '3WS',\n",
       "   '4WS',\n",
       "   '4WF',\n",
       "   'Unnamed: 9',\n",
       "   '2W.1',\n",
       "   '3WS.1',\n",
       "   '4WS.1',\n",
       "   '4WF.1'],\n",
       "  'battery_specific': ['Parameter',\n",
       "   'Value',\n",
       "   'Range',\n",
       "   'User Input?',\n",
       "   'Unnamed: 4',\n",
       "   'Same battery swapping station is used for 2W and 3W',\n",
       "   'Unnamed: 6',\n",
       "   'Unnamed: 7',\n",
       "   'Unnamed: 8',\n",
       "   'Unnamed: 9',\n",
       "   'Unnamed: 10',\n",
       "   'Unnamed: 11',\n",
       "   'Unnamed: 12',\n",
       "   'Unnamed: 13',\n",
       "   'Unnamed: 14',\n",
       "   'Unnamed: 15',\n",
       "   'Unnamed: 16',\n",
       "   'Unnamed: 17',\n",
       "   'Unnamed: 18',\n",
       "   'Unnamed: 19'],\n",
       "  'others': ['Range']},\n",
       " {'sites': ['Address',\n",
       "   'Traffic congestion',\n",
       "   'Year for Site recommendation',\n",
       "   'Hoarding/Kiosk (1 is yes & 0 is no)',\n",
       "   'Hoarding margin',\n",
       "   'Kiosk margin',\n",
       "   'Available area',\n",
       "   'Upfront cost per sqm (land)',\n",
       "   'Yearly cost per sqm (land)',\n",
       "   'Upfront cost per sqm (kiosk)',\n",
       "   'Yearly cost per sqm (kiosk)',\n",
       "   'Upfront cost per sqm (hoarding)',\n",
       "   'Yearly cost per sqm (hoarding)',\n",
       "   'Battery swap available']},\n",
       " {'profile': []},\n",
       " {'grid': ['Longitude',\n",
       "   'Latitude',\n",
       "   'Tariff',\n",
       "   'Power Outage',\n",
       "   'Available load']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verbose output\n",
    "data_integrity_check(m,s,t,g,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read global variables from xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def read_globals(m,s,t,g,ui_inputs):\n",
    "    \"This function returns all global parameters read from the xlsx.\"\n",
    "    \n",
    "    r = {}\n",
    "    df_c = m['charger_specific']\n",
    "    df_b = m['battery_specific']\n",
    "    df_o = m['others']\n",
    "    \n",
    "    # read all other parameters from the xlsx\n",
    "    \n",
    "    r['M'] = df_c[df_c['Parameter']=='vehicle_types']['Value'].iloc[0].split(',')\n",
    "    # or should it be from the UI having selected a subset for analysis?\n",
    "    r['M'] = ui_inputs['M']\n",
    "    r['C'] = df_c[df_c['Parameter']=='charger_types']['Value'].iloc[0].split(',')\n",
    "    r['Kj'] = eval(df_c[df_c['Parameter']=='Kj']['Value'].iloc[0])\n",
    "    r['Dj'] = eval(df_c[df_c['Parameter']=='Dj']['Value'].iloc[0])\n",
    "    r['Hj'] = eval(df_c[df_c['Parameter']=='Hj']['Value'].iloc[0])\n",
    "    r['Qj'] = eval(df_c[df_c['Parameter']=='Qj']['Value'].iloc[0])\n",
    "    r['tj'] = eval(df_c[df_c['Parameter']=='tj']['Value'].iloc[0])\n",
    "    r['Mj'] = eval(df_c[df_c['Parameter']=='Mj']['Value'].iloc[0])\n",
    "    r['Gk'] = eval(df_c[df_c['Parameter']=='Gk']['Value'].iloc[0])\n",
    "\n",
    "    r['N'] = 500\n",
    "    r['Ng'] = 0\n",
    "\n",
    "    r['timeslots'] = {k: 24/v for k, v in r['tj'].items()}\n",
    "    timeslots = r['timeslots']\n",
    "    \n",
    "    r['Nc'] = s['sites'].shape[0]\n",
    "    Nc = r['Nc']\n",
    "\n",
    "    r['Gi'] = [0]*Nc\n",
    "    r['di'] = [0]*Nc\n",
    "    r['Wi'] = [0]*Nc\n",
    "    r['Ri'] = [0]*Nc\n",
    "    r['Ai'] = [50]*Nc\n",
    "    r['Li'] = [1500]*Nc\n",
    "    r['Bi'] = [0.25 * 3.5 * 24 * 365]*Nc # 25% of Rs 3.5/KWh per year\n",
    "\n",
    "    r['Eg'] = {k: [5.5] * int(v) for k, v in timeslots.items()}\n",
    "    r['Er'] = {k: [0] * int(v) for k, v in timeslots.items()}\n",
    "    r['Mg'] = {k: [5.5 * 0.15] * int(v) for k, v in timeslots.items()}\n",
    "    r['Mr'] = {k: [0] * int(v) for k, v in timeslots.items()}\n",
    "    r['l']  = {k: [1] * int(v) for k, v in timeslots.items()}\n",
    "    \n",
    "    r['MH'] = [s['sites'].loc[i]['Hoarding margin'] for i in range(Nc)]\n",
    "    r['MK'] = [0.15]*Nc\n",
    "\n",
    "    #Traffic Model\n",
    "    # read hourly vehicular traffic from the traffic.xlsx else use default values\n",
    "    # peak vehicles through crowded junctions in a day ~ 1.5L\n",
    "\n",
    "    peak_traffic = [\n",
    "             4826, 4826, 5228, 5228, 5228, 5630, 6434, 6836, 6836, \n",
    "             6434, 6032, 6032, 6032, 6032, 6434, 6836, 7239, 8043, \n",
    "             8043, 8043, 6836, 6032, 5630, 5228       \n",
    "    ]\n",
    "\n",
    "    if 'profile' in t:\n",
    "      r['peak_traffic'] = t['profile'].vehicles.tolist()[:24] \n",
    "      peak_traffic = r['peak_traffic']\n",
    "    else:\n",
    "      printf(\"Using default traffic profile of around 55000 vehicles per day\")\n",
    "      r['peak_traffic'] = peak_traffic\n",
    "\n",
    "    # Average traffic approx 80% of peak\n",
    "    avg_traffic = [i*.8 for i in peak_traffic]\n",
    "    \n",
    "    avg_traffic_3W = [i*.4 for i in avg_traffic]\n",
    "    avg_traffic_4W = [i*.2 for i in avg_traffic]\n",
    "  \n",
    "    djworking_hourly_3WS = [i/5 for i in avg_traffic_3W]\n",
    "    djworking_hourly = [i/5 for i in avg_traffic_4W]\n",
    "    djworking_half_hourly = [val for val in djworking_hourly \n",
    "                             for _ in (0, 1)]\n",
    "    djworking_one_and_half_hourly = list(np.mean(np.array(djworking_half_hourly).reshape(-1, 3), axis=1))\n",
    "    r['djworking_hourly'] = djworking_hourly\n",
    "    r['djworking_half_hourly'] = djworking_half_hourly\n",
    "    r['djworking_one_and_half_hourly'] = djworking_one_and_half_hourly\n",
    "    \n",
    "    djworking = {}\n",
    "    djworking['3WS'] = [np.round(i,0) for i in djworking_hourly_3WS]\n",
    "    djworking['4WF'] = [np.round(i,0) for i in djworking_half_hourly]\n",
    "    djworking['4WS'] = [np.round(i,0) for i in djworking_one_and_half_hourly]\n",
    "    r['djworking'] = djworking        \n",
    "\n",
    "    r['Cij'] = {'3WS':[1]*Nc, '4WS': [1]*Nc, '4WF':[1]*Nc}\n",
    "    \n",
    "    # now override the defaults with the read values from the UI parameters into r\n",
    "    x = json.dumps(ui_inputs)\n",
    "    ui_inputs = json.loads(x)\n",
    "    \n",
    "    r['K'] = ui_inputs['years_of_analysis']\n",
    "    r['charger_types'] = ui_inputs['M']\n",
    "    r['years_of_analysis'] = ui_inputs['years_of_analysis']\n",
    "    r['capex_3WS'] = ui_inputs['capex_3WS']\n",
    "    r['capex_4WS'] = ui_inputs['capex_4WS']\n",
    "    r['capex_4WF'] = ui_inputs['capex_4WF']\n",
    "    r['hoarding_cost'] = 900000\n",
    "    r['kiosk_cost'] = 180000\n",
    "    r['year1_conversion'] = ui_inputs['year1_conversion']\n",
    "    r['year2_conversion'] = ui_inputs['year2_conversion']\n",
    "    r['year3_conversion'] = ui_inputs['year3_conversion']\n",
    "    r['fast_charging'] = ui_inputs['fast_charging']\n",
    "    r['slow_charging'] = ui_inputs['slow_charging']\n",
    "    r['holiday_percentage'] = ui_inputs['holiday_percentage']\n",
    "    \n",
    "    # now lets derive all other parameters that depend on the UI inputs.\n",
    "    r['CH'] = [r['hoarding_cost']]*Nc\n",
    "    r['CK'] = [r['kiosk_cost']]*Nc\n",
    "    r['pj'] = {1: r['year1_conversion'], \n",
    "          2: r['year2_conversion'], \n",
    "          3: r['year3_conversion']}\n",
    "\n",
    "    r['Pj'] = max(r['pj'].values()) \n",
    "\n",
    "    holiday_percentage = r['holiday_percentage']\n",
    "    djholiday = {}\n",
    "    djholiday['3WS'] = [np.round(i*holiday_percentage,0) for i in djworking_hourly_3WS]\n",
    "    djholiday['4WF'] = [np.round(i*holiday_percentage,0) for i in djworking_half_hourly]\n",
    "    djholiday['4WS'] = [np.round(i*holiday_percentage,0) for i in djworking_one_and_half_hourly]\n",
    "    r['djholiday'] = djholiday\n",
    "    \n",
    "    fast_charging = float(df_o[df_o['Parameter']=='slow charger margin']['Value'].iloc[0])\n",
    "    slow_charging = float(df_o[df_o['Parameter']=='fast charger margin']['Value'].iloc[0])\n",
    "\n",
    "    r['qjworking'] = {'4WS': [slow_charging] * int(timeslots['4WS']), \n",
    "                 '4WF': [fast_charging] * int(timeslots['4WF']), \n",
    "                 '3WS': [fast_charging + slow_charging] * int(timeslots['3WS']), \n",
    "                  }\n",
    "    r['qjholiday'] = {'4WS': [slow_charging] * int(timeslots['4WS']), \n",
    "                 '4WF': [fast_charging] * int(timeslots['4WF']), \n",
    "                 '3WS': [fast_charging + slow_charging] * int(timeslots['3WS']), \n",
    "                 }\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arguments`:\n",
    "\n",
    "1. `m`: dataframe of model parameters (from model.xlsx)\n",
    "2. `s`: dataframe of sites (from sites.xlsx)\n",
    "3. `t`: dataframe of traffic profile (from traffic.xlsx)\n",
    "4. `g`: dataframe of grid parameters (from grid.xlsx)\n",
    "5. `ui_inputs`: dictionary of all parameters selected by use from the frontend with the UI\n",
    "\n",
    "`Returns`:\n",
    "\n",
    "A dictionary with all hyperparameters required for the model to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3WS': 112000, '4WS': 250000, '4WF': 1500000}\n",
      "['3WS', '4WS', '4WF']\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "\n",
    "ui_inputs = { \n",
    "    \"backoff_factor\": 1,\n",
    "    \"M\": [\"3WS\", \"4WS\", \"4WF\"],\n",
    "    \"years_of_analysis\": [1,2,3],\n",
    "    \"capex_3WS\": 112000,\n",
    "    \"capex_4WS\": 250000,\n",
    "    \"capex_4WF\": 1500000,\n",
    "    \"hoarding cost\": 900000,\n",
    "    \"kiosk_cost\": 180000,\n",
    "    \"year1_conversion\": 0.02,\n",
    "    \"year2_conversion\": 0.05,\n",
    "    \"year3_conversion\": 0.1,\n",
    "    \"holiday_percentage\": 0.3,\n",
    "    \"fast_charging\": 0.3,\n",
    "    \"slow_charging\": 0.15,\n",
    "    \"cluster\": False,\n",
    "    \"cluster_th\": 0.2,\n",
    "    \"plot_dendrogram\": False,\n",
    "    \"use_defaults\": False \n",
    "}\n",
    "\n",
    "r = read_globals(m,s,t,g, ui_inputs)\n",
    "print(r['Kj'])\n",
    "print(r['charger_types'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
